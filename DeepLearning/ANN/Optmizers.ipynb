{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fd3b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ef00dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73761ba4",
   "metadata": {},
   "source": [
    "# HOW TO MAKE NUMBER OF NEURONS AS HYPERPARAMETRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9aa7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units=hp.Int(\"units\",min_value=32,max_value=512,step=32),\n",
    "            activation='relu'\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a3f15",
   "metadata": {},
   "source": [
    "# HOW TO MAKE OTHER PARAMETERS AS HYPERPARAMETRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fed7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units=hp.Int(\"units\",min_value=32,max_value=512,step=32),\n",
    "            activation=hp.Choice('activation',['relu','tanh'])\n",
    "        )\n",
    "    )\n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10,activation='softmax'))\n",
    "    learning_rate=hp.Float('lr',min_value=1e-4,max_value=1e-2,sampling='log')\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ddf0b",
   "metadata": {},
   "source": [
    "# HOW TO MAKE NUMBER OF LAYERS AS HYPERPARAMETRE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab9fcc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    for i in range(hp.Int('num_layers',1,3)):\n",
    "        \n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\",min_value=32,max_value=512,step=32),\n",
    "                activation=hp.Choice('activation',['relu','tanh'])\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    if hp.Boolean('batch_norm'):\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10,activation='softmax'))\n",
    "    learning_rate=hp.Float('lr',min_value=1e-4,max_value=1e-2,sampling='log')\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18ccc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "tuner=keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd258ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23dcaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(x_test,y_test)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f3fac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[:-10000]\n",
    "y_train=y[:-10000]\n",
    "x_val=x[-10000:]\n",
    "y_val=y[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8529fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.expand_dims(x_train,-1).astype('float32')/255.0\n",
    "x_val=np.expand_dims(x_val,-1).astype('float32')/255.0\n",
    "x_test=np.expand_dims(x_test,-1).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06119633",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_val=keras.utils.to_categorical(y_val,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "341157f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 51s]\n",
      "val_accuracy: 0.967199981212616\n",
      "\n",
      "Best val_accuracy So Far: 0.967199981212616\n",
      "Total elapsed time: 00h 05m 17s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train,y_train,epochs=2,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ffee70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "models=tuner.get_best_models(num_models=2)\n",
    "best_model=models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344cde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">970</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m75,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m970\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,714</span> (299.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,714\u001b[0m (299.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,522</span> (298.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,522\u001b[0m (298.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94e853c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir\\helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 96\n",
      "activation: tanh\n",
      "dropout: False\n",
      "batch_norm: True\n",
      "lr: 0.002949855433472653\n",
      "units_1: 512\n",
      "units_2: 384\n",
      "Score: 0.967199981212616\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 128\n",
      "activation: tanh\n",
      "dropout: False\n",
      "batch_norm: True\n",
      "lr: 0.0006805637517182109\n",
      "units_1: 96\n",
      "units_2: 32\n",
      "Score: 0.9644500017166138\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "activation: relu\n",
      "dropout: True\n",
      "batch_norm: False\n",
      "lr: 0.006944763609999221\n",
      "units_1: 32\n",
      "Score: 0.9610500037670135\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1ea28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
